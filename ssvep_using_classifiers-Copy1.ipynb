{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Cross Subject SSVEP\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "from pyriemann.estimation import Covariances as COVs\n",
    "from estimation import Covariances, mean, scm\n",
    "from classifiers import MDM, TangentSpace\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "import moabb\n",
    "from moabb.datasets import SSVEPExo,Nakanishi2015,Wang2016,MAMEM1,MAMEM2,MAMEM3\n",
    "from moabb.evaluations import CrossSubjectEvaluation,CrossSessionEvaluation,WithinSessionEvaluation\n",
    "from moabb.paradigms import SSVEP, FilterBankSSVEP\n",
    "from moabb.pipelines import SSVEP_CCA, ExtendedSSVEPSignal\n",
    "\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=RuntimeWarning)\n",
    "moabb.set_log_level(\"info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def huber_prime(x,r):\n",
    "    if x < r:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(signal,p=32):\n",
    "    n_sessions = signal.shape[0]//p\n",
    "    trains_idx,tests_idx = [],[]\n",
    "    for i in range(n_sessions):\n",
    "        test_idx = list(range(i*p,(i+1)*p))\n",
    "        train_idx=[]\n",
    "        for j in range(signal.shape[0]):\n",
    "            if not (j in test_idx):\n",
    "                train_idx.append(j)\n",
    "        trains_idx.append(train_idx)\n",
    "        tests_idx.append(test_idx)\n",
    "    return trains_idx,tests_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MAMEM1()\n",
    "#dataset.interval = [0.5,5]\n",
    "#dataset.subject_list = dataset.subject_list[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "[1, 4]\n"
     ]
    }
   ],
   "source": [
    "print(dataset.subject_list)\n",
    "print(dataset.interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = dataset.get_data()\n",
    "records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose paradigm\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paradigm_fb = FilterBankSSVEP(filters=None, n_classes=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classes are defined by the frequency of the stimulation, here we use\n",
    "the first two frequencies of the dataset, 13 and 17 Hz.\n",
    "The evaluation function uses a LabelEncoder, transforming them\n",
    "to 0 and 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = paradigm_fb.used_events(dataset)\n",
    "freqs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create pipelines\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = {}\n",
    "\n",
    "pipeline[\"MDM + scm covs\"] = make_pipeline(\n",
    "    ExtendedSSVEPSignal(),\n",
    "    COVs(estimator=\"scm\"),\n",
    "    MDM()\n",
    ")\n",
    "\n",
    "pipeline[\"MDM + lwf covs\"] = make_pipeline(\n",
    "    ExtendedSSVEPSignal(),\n",
    "    COVs(estimator=\"lwf\"),\n",
    "    MDM()\n",
    ")\n",
    "\n",
    "pipeline[\"MDM + huber covs\"] = make_pipeline(\n",
    "    ExtendedSSVEPSignal(),\n",
    "    Covariances(estimator=\"huber non adaptive\"),\n",
    "    MDM()\n",
    ")\n",
    "\n",
    "pipeline[\"MDM + tyler covs\"] = make_pipeline(\n",
    "    ExtendedSSVEPSignal(),\n",
    "    Covariances(estimator=\"tyler adaptive\"),\n",
    "    MDM()\n",
    ")\n",
    "\n",
    "pipeline[\"MDM + student covs\"] = make_pipeline(\n",
    "    ExtendedSSVEPSignal(),\n",
    "    Covariances(estimator=\"student\"),\n",
    "    MDM()\n",
    ")\n",
    "\n",
    "ddl = 5\n",
    "n= 32 #adapt with number of classes\n",
    "clean_prop = 0.9\n",
    "\n",
    "\n",
    "param1 = 0.5*scipy.stats.chi2.ppf(clean_prop,2*n)\n",
    "u_prime1 = lambda x : huber_prime(x,param1)\n",
    "pipeline[\"rMDM with huber + scm covs\"] = make_pipeline(\n",
    "    ExtendedSSVEPSignal(),\n",
    "    Covariances(estimator=\"scm\"),\n",
    "    MDM(u_prime= u_prime1 )\n",
    ")\n",
    "\n",
    "pipeline[\"rMDM with student + scm covs\"] = make_pipeline(\n",
    "    ExtendedSSVEPSignal(),\n",
    "    COVs(estimator=\"scm\"),\n",
    "    MDM(u_prime = lambda x : (n+0.5*ddl)/(0.5*ddl+x))\n",
    ")\n",
    "\n",
    "\n",
    "pipeline[\"rMDM with tyler + scm covs\"] = make_pipeline(\n",
    "    ExtendedSSVEPSignal(),\n",
    "    COVs(estimator=\"scm\"),\n",
    "    MDM(u_prime = lambda x : n/x)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, metadata = paradigm_fb.get_data(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictio={}\n",
    "for i in range(len(freqs)):\n",
    "    dictio[freqs[i]]=i+1\n",
    "print(dictio)\n",
    "import numpy as np\n",
    "y_= [dictio[y[l]] for l in range(len(y))]\n",
    "y =np.asarray(y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signals = []\n",
    "labels=[]\n",
    "n_sessions=[]\n",
    "n = 0\n",
    "for subject in dataset.subject_list :\n",
    "    n_session = len(records[subject]['session_0'])\n",
    "    n_sessions.append(n_session)\n",
    "    m =32*n_session +n\n",
    "    signals.append(X[n:m])\n",
    "    labels.append(y[n:m])\n",
    "    n=m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "The evaluation will return a dataframe containing a single AUC score for\n",
    "each subject / session of the dataset, and for each pipeline.\n",
    "\n",
    "Results are saved into the database, so that if you add a new pipeline, it\n",
    "will not run again the evaluation unless a parameter has changed. Results can\n",
    "be overwritten if necessary.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\"subject\":[],\"score\":[],\"train samples\":[], \"test samples\":[], \"pipeline\":[]}\n",
    "for k in pipeline.keys():\n",
    "    clf= pipeline[k]\n",
    "    print(clf)\n",
    "    for i in tqdm(range(len(dataset.subject_list))):\n",
    "        accs= []\n",
    "        subject = dataset.subject_list[i]\n",
    "        signal,n_session,label = signals[i],n_sessions[i],labels[i]\n",
    "        trains_idx,tests_idx = split(signal,n_session)\n",
    "        for train_idx,test_idx in zip(trains_idx,tests_idx):\n",
    "            X_train,X_test = signal[train_idx],signal[test_idx]\n",
    "            y_train,y_test = label[train_idx],label[test_idx]\n",
    "            clf.fit(X_train,y_train)\n",
    "            preds= clf.predict(X_test)\n",
    "            acc = np.mean(preds==y_test)\n",
    "            accs.append(acc)\n",
    "        results[\"subject\"].append(subject)\n",
    "        results[\"score\"].append(np.mean(accs))\n",
    "        results[\"pipeline\"].append(k)\n",
    "        results[\"train samples\"].append(len(train_idx))\n",
    "        results[\"test samples\"].append(len(test_idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter bank processing, determine automatically the filter from the\n",
    "stimulation frequency values of events.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Results\n",
    "\n",
    "Here we plot the results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "sns.barplot(data=df, y=\"score\", x=\"subject\", hue=\"pipeline\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in range(len(list(pipeline.keys()))):\n",
    "    mean_  = 0\n",
    "    for i in range(12):\n",
    "        mean_ += df.loc[i+12*m].at['score']\n",
    "    print(df.loc[12*m].at['pipeline'], \"=\",mean_/12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross session evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross_session\n",
    "\n",
    "evaluation1 = WithinSessionEvaluation(\n",
    "    paradigm=paradigm_fb, datasets=dataset, overwrite=False\n",
    ")\n",
    "results1 = evaluation1.process(pipeline)\n",
    "\n",
    "results1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "sns.barplot(data=results1, y=\"score\", x=\"subject\", hue=\"pipeline\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(results1)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in range(len(list(pipeline.keys()))):\n",
    "    mean_  = 0\n",
    "    for i in range(12):\n",
    "        mean_ += df1.loc[i+12*m].at['score']\n",
    "    print(df1.loc[12*m].at['pipeline'], \"=\",mean_/12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
